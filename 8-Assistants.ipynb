{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64047ce1-280d-401d-acc6-27b0b8bf9628",
   "metadata": {},
   "source": [
    "## Assistants API overview\n",
    "Build AI Assistants with essential tools and integrations.\n",
    "The Assistants API allows you to build AI assistants within your own applications. An Assistant has instructions and can leverage models, tools, and files to respond to user queries. The Assistants API currently supports three types of tools: Code Interpreter, File Search, and Function calling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0745347f-d060-4478-84b0-3cb37fe7f189",
   "metadata": {},
   "source": [
    "### Step 1: Create an Assistant\n",
    "An Assistant represents an entity that can be configured to respond to a user's messages using several parameters like model, instructions, and tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2829ab9-8e61-4c36-9417-09b466a40f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Math Tutor\",\n",
    "  instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "  model=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759934ab-a36a-477e-b12e-33b7bb89dedf",
   "metadata": {},
   "source": [
    "### Step 2: Create a Thread\n",
    "A Thread represents a conversation between a user and one or many Assistants. You can create a Thread when a user (or your AI application) starts a conversation with your Assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446edbb-d4b4-4ce0-8c44-157494cc1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e9aa85-0b4e-4099-94ef-681ed809c82b",
   "metadata": {},
   "source": [
    "### Step 3: Add a Message to the Thread\n",
    "The contents of the messages your users or applications create are added as Message objects to the Thread. Messages can contain both text and files. There is a limit of 100,000 Messages per Thread and we smartly truncate any context that does not fit into the model's context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db40ae-b4e0-49fd-ab54-4e9d93b8c614",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d4aae-57a0-4aec-be1d-8ac653d78687",
   "metadata": {},
   "source": [
    "### Step 4: Create a Run\n",
    "Once all the user Messages have been added to the Thread, you can __Run__ the Thread with any Assistant. Creating a Run uses the model and tools associated with the Assistant to generate a response. These responses are added to the Thread as __assistant__ Messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111834e4-7811-447d-b1b7-9bdd257984bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and Stream a Run\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    " \n",
    "# First, we create a EventHandler class to define\n",
    "# how we want to handle the events in the response stream.\n",
    " \n",
    "class EventHandler(AssistantEventHandler):    \n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "      \n",
    "  @override\n",
    "  def on_text_delta(self, delta, snapshot):\n",
    "    print(delta.value, end=\"\", flush=True)\n",
    "      \n",
    "  def on_tool_call_created(self, tool_call):\n",
    "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "  \n",
    "  def on_tool_call_delta(self, delta, snapshot):\n",
    "    if delta.type == 'code_interpreter':\n",
    "      if delta.code_interpreter.input:\n",
    "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "      if delta.code_interpreter.outputs:\n",
    "        print(f\"\\n\\noutput >\", flush=True)\n",
    "        for output in delta.code_interpreter.outputs:\n",
    "          if output.type == \"logs\":\n",
    "            print(f\"\\n{output.logs}\", flush=True)\n",
    " \n",
    "# Then, we use the `stream` SDK helper \n",
    "# with the `EventHandler` class to create the Run \n",
    "# and stream the response.\n",
    " \n",
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n",
    "  event_handler=EventHandler(),\n",
    ") as stream:\n",
    "  stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d39ad-10d1-439a-82cc-8e5a416fef86",
   "metadata": {},
   "source": [
    "\n",
    "Runs are asynchronous, which means you'll want to monitor their __status__ by polling the Run object until a terminal status is reached. For convenience, the 'create and poll' SDK helpers assist both in creating the run and then polling for its completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57733984-1e39-4021-be62-f57884042b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without Streaming\n",
    "#Create a Run\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please address the user as Jane Doe. The user has a premium account.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199dc3f2-398e-4e92-8def-259f06c9db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run.status == 'completed': \n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "else:\n",
    "  print(run.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d69502f-00be-4e1c-94c1-92e2e3b6381f",
   "metadata": {},
   "source": [
    "## Creating Assistants\n",
    "For example, to create an Assistant that can create data visualization based on a .csv file, first upload a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ab342b-51c0-4e11-91ca-f312d1458cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "    file = open(\"revenue_forecast.csv\", \"rb\"),\n",
    "    purpose = 'assistants'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f2e07-accc-45ac-98b0-8a5a89a006af",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Data visualizer\",\n",
    "  description=\"You are great at creating beautiful data visualizations. You analyze data present in .csv files, understand trends, and come up with data visualizations relevant to those trends. You also share a brief text summary of the trends observed.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "  tool_resources={\n",
    "    \"code_interpreter\": {\n",
    "      \"file_ids\": [file.id]\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4855a05d-48a6-4fd6-b4f2-7d16aa5b27fd",
   "metadata": {},
   "source": [
    "You can attach a maximum of 20 files to code_interpreter and 10,000 files to file_search (using vector_store objects).\n",
    "\n",
    "Each file can be at most 512 MB in size and have a maximum of 5,000,000 tokens. By default, the size of all the files uploaded in your project cannot exceed 100 GB, but you can reach out to our support team to increase this limit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63598d23-afbd-4507-9c1c-b0c37cbc17d5",
   "metadata": {},
   "source": [
    "### Managing Threads and Messages\n",
    "Threads and Messages represent a conversation session between an Assistant and a user. There is a limit of 100,000 Messages per Thread. Once the size of the Messages exceeds the context window of the model, the Thread will attempt to smartly truncate messages, before fully dropping the ones it considers the least important.\n",
    "\n",
    "You can create a Thread with an initial list of Messages like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7951679e-7af5-45ff-9361-b0085ff54ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Create a 3 data visualizations based on the trends in this file.\",\n",
    "            \"attachments\": [\n",
    "                {\n",
    "                    \"file_id\": file.id,\n",
    "                    \"tools\": [{\"type\": \"code_interpreter\"}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c789417e-49aa-4c94-961e-fc54c6cb2a95",
   "metadata": {},
   "source": [
    "### Creating image input content\n",
    "Message content can contain either external image URLs or File IDs uploaded via the File API. Only models with Vision support can accept image input. Supported image content types include png, jpg, gif, and webp. When creating image files, pass __purpose=\"vision\"__ to allow you to later download and display the input content. Currently, there is a 100GB limit per project. Please contact us to request a limit increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b45873-6d9b-473b-b3ec-6fffc839e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "    file = open(\"myimage.png\", \"rb\"),\n",
    "    purpose = \"vision\"\n",
    ")\n",
    "thread = client.threads.create(\n",
    "    messages =[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What is difference between these images?\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"https://example.com/image.png\"}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_file\",\n",
    "                    \"image_file\": {\"file_id\": file.id}\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26442c4b-abd0-42d6-b35d-bd7d5a7d3e3f",
   "metadata": {},
   "source": [
    "### Low or high fidelity image understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e86522-161a-4f8b-b642-af370f9d59fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What is this an image of?\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://example.com/image.png\",\n",
    "            \"detail\": \"high\"\n",
    "          }\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70a1112-92bb-4e67-a4e1-230e5f84135a",
   "metadata": {},
   "source": [
    "### Message annotations\n",
    "Messages created by Assistants may contain annotations within the content array of the object. Annotations provide information around how you should annotate the text in the Message.\n",
    "\n",
    "There are two types of Annotations:\n",
    "\n",
    "- file_citation: File citations are created by the __file_search__ tool and define references to a specific file that was uploaded and used by the Assistant to generate the response.\n",
    "- file_path: File path annotations are created by the __code_interpreter__ tool and contain references to the files generated by the tool.\n",
    "  \n",
    "When annotations are present in the Message object, you'll see illegible model-generated substrings in the text that you should replace with the annotations. These strings may look something like 【13†source】 or sandbox:/mnt/data/file.csv. Here’s an example python code snippet that replaces these strings with the annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc8d53-88b1-4d2c-9075-19963813f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the message object\n",
    "# Retrieve the message object\n",
    "message = client.beta.threads.messages.retrieve(\n",
    "  thread_id=\"...\",\n",
    "  message_id=\"...\"\n",
    ")\n",
    "\n",
    "# Extract the message content\n",
    "message_content = message.content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "\n",
    "# Iterate over the annotations and add footnotes\n",
    "for index, annotation in enumerate(annotations):\n",
    "    # Replace the text with a footnote\n",
    "    message_content.value = message_content.value.replace(annotation.text, f' [{index}]')\n",
    "    \n",
    "    # Gather citations based on annotation attributes\n",
    "    if (file_citation := getattr(annotation, 'file_citation', None)):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f'[{index}] {file_citation.quote} from {cited_file.filename}')\n",
    "    elif (file_path := getattr(annotation, 'file_path', None)):\n",
    "        cited_file = client.files.retrieve(file_path.file_id)\n",
    "        citations.append(f'[{index}] Click <here> to download {cited_file.filename}')\n",
    "        # Note: File download functionality not implemented above for brevity\n",
    "\n",
    "# Add footnotes to the end of the message before displaying to user\n",
    "message_content.value += '\\n' + '\\n'.join(citations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaacd1c2-c586-43f9-8d73-7bde9905c2ab",
   "metadata": {},
   "source": [
    "### Runs and Run Steps\n",
    "When you have all the context you need from your user in the Thread, you can run the Thread with an Assistant of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7721a4-e067-4c5c-bba9-7e6679e66e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77fab40-8e0e-4300-a851-7aceff7d39bd",
   "metadata": {},
   "source": [
    "By default, a Run will use the __model__ and __tools__ configuration specified in Assistant object, but you can override most of these when creating the Run for added flexibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94389335-bcc2-44f1-95bd-acf06c41a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  model=\"gpt-4o\",\n",
    "  instructions=\"New instructions that override the Assistant instructions\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"file_search\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a89c2cc-5bdf-4dfd-93a4-1c69585608b2",
   "metadata": {},
   "source": [
    "### Assistants API tools\n",
    "Explore tools for file search, code, and function calling.\n",
    "\n",
    "The Assistants API currently supports the following tools:\n",
    "\n",
    "- __File Search:__\n",
    "Built-in RAG tool to process and search through files\n",
    "\n",
    "- __Code Interprete:__\n",
    "Write and run python code, process files and diverse data\n",
    "\n",
    "- __Function Calling:__\n",
    "Use your own custom functions to interact with your application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ba5c94-d92c-43c6-9667-fcc7335f403b",
   "metadata": {},
   "source": [
    "### File Search\n",
    "#### Step 1: Create a new Assistant with File Search Enabled\n",
    "Create a new assistant with __file_search__ enabled in the __tools__ parameter of the Assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf17b0-cee9-46fb-88c5-839764ac0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Financial Analyst Assistant\",\n",
    "  instructions=\"You are an expert financial analyst. Use you knowledge base to answer questions about audited financial statements.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80216315-657e-4f71-988f-4319d90f62e6",
   "metadata": {},
   "source": [
    "#### Step 2: Upload files and add them to a Vector Store\n",
    "To access your files, the __file_search__ tool uses the Vector Store object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48fbb7-1d9b-4873-9511-aff7b5d911dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector store caled \"Financial Statements\"\n",
    "vector_store = client.vector_stores.create(name=\"Financial Statements\")\n",
    "\n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [\"edgar/goog-10k.pdf\", \"edgar/brka-10k.txt\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0aac8-0083-425e-9ef8-d7037a421037",
   "metadata": {},
   "source": [
    "### Step 3: Update the assistant to use the new Vector Store\n",
    "To make the files accessible to your assistant, update the assistant’s __tool_resources__ with the new __vector_store__ id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd55da92-fcdb-4e5e-a4ec-75bfb579d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907e33b-6a14-4eb1-9b89-74aa8a25e914",
   "metadata": {},
   "source": [
    "#### Step 4: Create a thread\n",
    "You can also attach files as Message attachments on your thread. Doing so will create another vector_store associated with the thread, or, if there is already a vector store attached to this thread, attach the new files to the existing thread vector store. When you create a Run on this thread, the file search tool will query both the vector_store from your assistant and the vector_store on the thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21de0d-e23d-4f68-987e-10181052577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the user provided file to OpenAI\n",
    "message_file = client.files.create(\n",
    "  file=open(\"edgar/aapl-10k.pdf\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"How many shares of AAPL were outstanding at the end of of October 2023?\",\n",
    "      # Attach the new file to the message.\n",
    "      \"attachments\": [\n",
    "        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "# The thread now has a vector store with that file in its tool resources.\n",
    "print(thread.tool_resources.file_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc29254-298a-4829-9032-0f31c0124180",
   "metadata": {},
   "source": [
    "#### Step 5: Create a run and check the output\n",
    "Now, create a Run and observe that the model uses the File Search tool to provide a response to the user’s question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50999b07-6ee2-4406-858e-07f284ceed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Streaming\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler, OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_message_done(self, message) -> None:\n",
    "        # print a citation to the file searched\n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, f\"[{index}]\"\n",
    "            )\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "        print(message_content.value)\n",
    "        print(\"\\n\".join(citations))\n",
    "\n",
    "# Then, we use the stream SDK helper\n",
    "# with the EventHandler class to create the Run\n",
    "# and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ccde5-2ba2-4c54-b27a-3dc1ad245d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the create and poll SDK helper to create a run and poll the status of\n",
    "# the run until it's in a terminal state.\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "print(message_content.value)\n",
    "print(\"\\n\".join(citations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90623b88-77e4-4c2e-a90c-cbe89be717e3",
   "metadata": {},
   "source": [
    "#### Creating vector stores and adding files\n",
    "You can create a vector store and add files to it in a single API call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a55337-c7d0-4614-bf4f-c19b03ddaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "  name=\"Product Documentation\",\n",
    "  file_ids=['file_1', 'file_2', 'file_3', 'file_4', 'file_5']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4993c2-0ed8-4ff7-a95c-72be7f3d5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.vector_stores.files.create_and_poll(\n",
    "  vector_store_id=\"vs_abc123\",\n",
    "  file_id=\"file-abc123\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f84e0-1673-41e1-8ed4-e4fc7be40666",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = client.vector_stores.file_batches.create_and_poll(\n",
    "  vector_store_id=\"vs_abc123\",\n",
    "  file_ids=['file_1', 'file_2', 'file_3', 'file_4', 'file_5']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947fa85d-6558-4516-b730-ce1d9cf2d37d",
   "metadata": {},
   "source": [
    "#### Attaching vector stores\n",
    "You can attach vector stores to your Assistant or Thread using the tool_resources parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbbb9fa-f7a0-455b-88ac-d5e555e6dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a helpful product support assistant and you answer questions based on the files provided to you.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    "  tool_resources={\n",
    "    \"file_search\": {\n",
    "      \"vector_store_ids\": [\"vs_1\"]\n",
    "    }\n",
    "  }\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[ { \"role\": \"user\", \"content\": \"How do I cancel my subscription?\"} ],\n",
    "  tool_resources={\n",
    "    \"file_search\": {\n",
    "      \"vector_store_ids\": [\"vs_2\"]\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d17b12a-40ef-45b7-963b-68f019563dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include file search results in response when creating a run\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "srun_step = client.beta.threads.runs.steps.retrieve(\n",
    "    thread_id=\"thread_abc123\",\n",
    "    run_id=\"run_abc123\",\n",
    "    step_id=\"step_abc123\",\n",
    "    include=[\"step_details.tool_calls[*].file_search.results[*].content\"]\n",
    ")\n",
    "\n",
    "print(run_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97a890-e7ac-443e-8aa9-62cf5b37c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = client.vector_stores.create_and_poll(\n",
    "  name=\"Product Documentation\",\n",
    "  file_ids=['file_1', 'file_2', 'file_3', 'file_4', 'file_5'],\n",
    "  expires_after={\n",
    "    \"anchor\": \"last_active_at\",\n",
    "    \"days\": 7\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210cbd6-2cdf-4154-90d7-2a5e8605fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = list(client.vector_stores.files.list(\"vs_expired\"))\n",
    "\n",
    "vector_store = client.vector_stores.create(name=\"rag-store\")\n",
    "client.beta.threads.update(\n",
    "    \"thread_abc123\",\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")\n",
    "\n",
    "for file_batch in chunked(all_files, 100):\n",
    "    client.vector_stores.file_batches.create_and_poll(\n",
    "        vector_store_id=vector_store.id, file_ids=[file.id for file in file_batch]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d602e05-df99-4402-aab0-7a4613341cab",
   "metadata": {},
   "source": [
    "## Code Interpreter\n",
    "Code Interpreter allows Assistants to write and run Python code in a sandboxed execution environment. This tool can process files with diverse data and formatting, and generate files with data and images of graphs. Code Interpreter allows your Assistant to run code iteratively to solve challenging code and math problems. When your Assistant writes code that fails to run, it can iterate on this code by attempting to run different code until the code execution succeeds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190e3d4-188c-49f9-bdea-d8a6a3608d00",
   "metadata": {},
   "source": [
    "### Enabling Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1cde5c-faa0-484d-a850-e7d2320679f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a personal math tutor. When asked a math question, write and run code to answer the question.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef05909-46fb-4771-95e6-38eaf5c8565f",
   "metadata": {},
   "source": [
    "### Passing files to Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6d415-2640-48f5-8742-c60c80325e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a file with an \"assistants\" purpose\n",
    "file = client.files.create(\n",
    "  file=open(\"mydata.csv\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n",
    "\n",
    "# Create an assistant using the file ID\n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a personal math tutor. When asked a math question, write and run code to answer the question.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "  tool_resources={\n",
    "    \"code_interpreter\": {\n",
    "      \"file_ids\": [file.id]\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c784637-55ef-4329-afe1-a1c95a2cdba3",
   "metadata": {},
   "source": [
    "Files can also be passed at the Thread level. These files are only accessible in the specific Thread. Upload the File using the File upload endpoint and then pass the File ID as part of the Message creation request:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca51dc-c8ad-4a42-8fea-05738430ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I need to solve the equation '3x + 11 = 14'. Can you help?\",\n",
    "            \"attachments\": [\n",
    "                {\n",
    "                \"file_id\": file.id,\n",
    "                \"tools\": [{\"type\": \"code_interpreter\"}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cee15b-1003-4486-94d0-3b1ed0b7bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "\t\"id\": \"msg_abc123\",\n",
    "\t\"object\": \"thread.message\",\n",
    "\t\"created_at\": 1698964262,\n",
    "\t\"thread_id\": \"thread_abc123\",\n",
    "\t\"role\": \"assistant\",\n",
    "\t\"content\": [\n",
    "    {\n",
    "      \"type\": \"image_file\",\n",
    "      \"image_file\": {\n",
    "        \"file_id\": \"file-abc123\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "  # ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d91f5-4669-4696-9d43-bf078fb7140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The file content can then be downloaded by passing the file ID to the Files API:\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "image_data = client.files.content(\"file-abc123\")\n",
    "image_data_bytes = image_data.read()\n",
    "\n",
    "with open(\"./my-image.png\", \"wb\") as file:\n",
    "    file.write(image_data_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801c5e86-e38c-46ba-9e29-3afdd85268fa",
   "metadata": {},
   "source": [
    "### Input and output logs of Code Interpreter\n",
    "By listing the steps of a Run that called Code Interpreter, you can inspect the code input and outputs logs of Code Interpreter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96c59e-21fc-4bdd-88cf-13e3c637d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = client.beta.threads.runs.steps.list(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b066a25-0b14-4ee1-a2a4-8d7d2ef916f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"object\": \"list\",\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"id\": \"step_abc123\",\n",
    "      \"object\": \"thread.run.step\",\n",
    "      \"type\": \"tool_calls\",\n",
    "      \"run_id\": \"run_abc123\",\n",
    "      \"thread_id\": \"thread_abc123\",\n",
    "      \"status\": \"completed\",\n",
    "      \"step_details\": {\n",
    "        \"type\": \"tool_calls\",\n",
    "        \"tool_calls\": [\n",
    "          {\n",
    "            \"type\": \"code\",\n",
    "            \"code\": {\n",
    "              \"input\": \"# Calculating 2 + 2\\\\nresult = 2 + 2\\\\nresult\",\n",
    "              \"outputs\": [\n",
    "                {\n",
    "                  \"type\": \"logs\",\n",
    "                  \"logs\": \"4\"\n",
    "                }\n",
    "\t\t\t\t\t\t...\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51668548-e698-4124-8312-5bd952bc3138",
   "metadata": {},
   "source": [
    "## Function Calling\n",
    "Similar to the Chat Completions API, the Assistants API supports function calling. Function calling allows you to describe functions to the Assistants API and have it intelligently return the functions that need to be called along with their arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c3ab52-0569-4be3-a154-5dae0bd0eb8d",
   "metadata": {},
   "source": [
    "### Step 1: Define functions\n",
    "When creating your assistant, you will first define the functions under the tools param of the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef5e4993-cab1-40b4-9b02-8f99d14ebf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    " \n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a weather bot. Use the provided functions to answer questions.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_current_temperature\",\n",
    "        \"description\": \"Get the current temperature for a specific location\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"location\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The city and state, e.g., San Francisco, CA\"\n",
    "            },\n",
    "            \"unit\": {\n",
    "              \"type\": \"string\",\n",
    "              \"enum\": [\"Celsius\", \"Fahrenheit\"],\n",
    "              \"description\": \"The temperature unit to use. Infer this from the user's location.\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\"location\", \"unit\"]\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_rain_probability\",\n",
    "        \"description\": \"Get the probability of rain for a specific location\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"location\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The city and state, e.g., San Francisco, CA\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\"location\"]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e755562-d36d-402a-9a12-9244aa112874",
   "metadata": {},
   "source": [
    "### Step 2: Create a Thread and add Messages\n",
    "Create a Thread when a user starts a conversation and add Messages to the Thread as the user asks questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3dbb75-8f85-42d3-9759-9b6db5e44a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()\n",
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=\"What's the weather in San Francisco today and the likelihood it'll rain?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca1463-dceb-415a-a0a2-d113f8000383",
   "metadata": {},
   "source": [
    "### Step 3: Initiate a Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc20b8ae-c784-416a-909e-24b9b9f39e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Streaming\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    " \n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_event(self, event):\n",
    "      # Retrieve events that are denoted with 'requires_action'\n",
    "      # since these will have our tool_calls\n",
    "      if event.event == 'thread.run.requires_action':\n",
    "        run_id = event.data.id  # Retrieve the run ID from the event data\n",
    "        self.handle_requires_action(event.data, run_id)\n",
    " \n",
    "    def handle_requires_action(self, data, run_id):\n",
    "      tool_outputs = []\n",
    "        \n",
    "      for tool in data.required_action.submit_tool_outputs.tool_calls:\n",
    "        if tool.function.name == \"get_current_temperature\":\n",
    "          tool_outputs.append({\"tool_call_id\": tool.id, \"output\": \"57\"})\n",
    "        elif tool.function.name == \"get_rain_probability\":\n",
    "          tool_outputs.append({\"tool_call_id\": tool.id, \"output\": \"0.06\"})\n",
    "        \n",
    "      # Submit all tool_outputs at the same time\n",
    "      self.submit_tool_outputs(tool_outputs, run_id)\n",
    " \n",
    "    def submit_tool_outputs(self, tool_outputs, run_id):\n",
    "      # Use the submit_tool_outputs_stream helper\n",
    "      with client.beta.threads.runs.submit_tool_outputs_stream(\n",
    "        thread_id=self.current_run.thread_id,\n",
    "        run_id=self.current_run.id,\n",
    "        tool_outputs=tool_outputs,\n",
    "        event_handler=EventHandler(),\n",
    "      ) as stream:\n",
    "        for text in stream.text_deltas:\n",
    "          print(text, end=\"\", flush=True)\n",
    "        print()\n",
    " \n",
    " \n",
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  event_handler=EventHandler()\n",
    ") as stream:\n",
    "  stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cfc91e-ee22-409a-8b64-d54e35694e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without Streaming\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")\n",
    " \n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "else:\n",
    "  print(run.status)\n",
    " \n",
    "# Define the list to store tool outputs\n",
    "tool_outputs = []\n",
    " \n",
    "# Loop through each tool in the required action section\n",
    "for tool in run.required_action.submit_tool_outputs.tool_calls:\n",
    "  if tool.function.name == \"get_current_temperature\":\n",
    "    tool_outputs.append({\n",
    "      \"tool_call_id\": tool.id,\n",
    "      \"output\": \"57\"\n",
    "    })\n",
    "  elif tool.function.name == \"get_rain_probability\":\n",
    "    tool_outputs.append({\n",
    "      \"tool_call_id\": tool.id,\n",
    "      \"output\": \"0.06\"\n",
    "    })\n",
    " \n",
    "# Submit all tool outputs at once after collecting them in a list\n",
    "if tool_outputs:\n",
    "  try:\n",
    "    run = client.beta.threads.runs.submit_tool_outputs_and_poll(\n",
    "      thread_id=thread.id,\n",
    "      run_id=run.id,\n",
    "      tool_outputs=tool_outputs\n",
    "    )\n",
    "    print(\"Tool outputs submitted successfully.\")\n",
    "  except Exception as e:\n",
    "    print(\"Failed to submit tool outputs:\", e)\n",
    "else:\n",
    "  print(\"No tool outputs to submit.\")\n",
    " \n",
    "if run.status == 'completed':\n",
    "  messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id\n",
    "  )\n",
    "  print(messages)\n",
    "else:\n",
    "  print(run.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e450ef-c321-485e-af25-646a98c85f8a",
   "metadata": {},
   "source": [
    "### Using Structured Outputs\n",
    "When you enable Structured Outputs by supplying strict: true, the OpenAI API will pre-process your supplied schema on your first request, and then use this artifact to constrain the model to your schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c40cc3-c2a7-4ef6-b5c7-9e4be13e63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    " \n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a weather bot. Use the provided functions to answer questions.\",\n",
    "  model=\"gpt-4o-2024-08-06\",\n",
    "  tools=[\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_current_temperature\",\n",
    "        \"description\": \"Get the current temperature for a specific location\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"location\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The city and state, e.g., San Francisco, CA\"\n",
    "            },\n",
    "            \"unit\": {\n",
    "              \"type\": \"string\",\n",
    "              \"enum\": [\"Celsius\", \"Fahrenheit\"],\n",
    "              \"description\": \"The temperature unit to use. Infer this from the user's location.\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\"location\", \"unit\"],\n",
    "          \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_rain_probability\",\n",
    "        \"description\": \"Get the probability of rain for a specific location\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"location\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The city and state, e.g., San Francisco, CA\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\"location\"],\n",
    "          \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
