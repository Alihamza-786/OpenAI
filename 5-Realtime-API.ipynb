{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f9414d-1986-40b5-a101-0f47f1f43c26",
   "metadata": {},
   "source": [
    "## Realtime API\n",
    "The OpenAI Realtime API enables you to build low-latency, multi-modal conversational experiences with expressive voice-enabled models. These models support realtime text and audio inputs and outputs, voice activation detection, function calling, and much more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3573ff-455c-4871-be3f-efb7f325335a",
   "metadata": {},
   "source": [
    "### Realtime API with WebRTC (Web Real-Time Communication)\n",
    "\n",
    "Use WebRTC to connect client-side applications to the Realtime API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d080787f-6a8e-4490-b31a-3e3b370e9dae",
   "metadata": {},
   "source": [
    "### Overview\n",
    "In scenarios where you would like to connect to a Realtime model from an insecure client over the network (like a web browser), we recommend using the WebRTC connection method. WebRTC is better equipped to handle variable connection states, and provides a number of convenient APIs for capturing user audio inputs and playing remote audio streams from the model.\n",
    "\n",
    "Connecting to the Realtime API from the browser should be done with an ephemeral API key, generated via the OpenAI REST API. The process for initializing a WebRTC connection is as follows (assuming a web browser client):\n",
    "\n",
    "1. A browser makes a request to a developer-controlled server to mint an ephemeral API key.\n",
    "2. The developer's server uses a standard API key to request an ephemeral key from the OpenAI REST API, and returns that new key to the browser. Note that ephemeral keys currently expire one minute after being issued.\n",
    "3. The browser uses the ephemeral key to authenticate a session directly with the OpenAI Realtime API as a WebRTC peer connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6cfb8-c4c6-4d62-82af-8f114ee2411d",
   "metadata": {},
   "source": [
    "The following example shows how to initialize a WebRTC session (including the data channel to send and receive Realtime API events). It assumes you have already fetched an ephemeral API token (example server code for this can be found in the next section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef5b16-92d9-4f97-b8cb-0b42d96f8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "async function init() {\n",
    "  // Get an ephemeral key from your server - see server code below\n",
    "  const tokenResponse = await fetch(\"/session\");\n",
    "  const data = await tokenResponse.json();\n",
    "  const EPHEMERAL_KEY = data.client_secret.value;\n",
    "\n",
    "  // Create a peer connection\n",
    "  const pc = new RTCPeerConnection();\n",
    "\n",
    "  // Set up to play remote audio from the model\n",
    "  const audioEl = document.createElement(\"audio\");\n",
    "  audioEl.autoplay = true;\n",
    "  pc.ontrack = e => audioEl.srcObject = e.streams[0];\n",
    "\n",
    "  // Add local audio track for microphone input in the browser\n",
    "  const ms = await navigator.mediaDevices.getUserMedia({\n",
    "    audio: true\n",
    "  });\n",
    "  pc.addTrack(ms.getTracks()[0]);\n",
    "\n",
    "  // Set up data channel for sending and receiving events\n",
    "  const dc = pc.createDataChannel(\"oai-events\");\n",
    "  dc.addEventListener(\"message\", (e) => {\n",
    "    // Realtime server events appear here!\n",
    "    console.log(e);\n",
    "  });\n",
    "\n",
    "  // Start the session using the Session Description Protocol (SDP)\n",
    "  const offer = await pc.createOffer();\n",
    "  await pc.setLocalDescription(offer);\n",
    "\n",
    "  const baseUrl = \"https://api.openai.com/v1/realtime\";\n",
    "  const model = \"gpt-4o-realtime-preview-2024-12-17\";\n",
    "  const sdpResponse = await fetch(`${baseUrl}?model=${model}`, {\n",
    "    method: \"POST\",\n",
    "    body: offer.sdp,\n",
    "    headers: {\n",
    "      Authorization: `Bearer ${EPHEMERAL_KEY}`,\n",
    "      \"Content-Type\": \"application/sdp\"\n",
    "    },\n",
    "  });\n",
    "\n",
    "  const answer = {\n",
    "    type: \"answer\",\n",
    "    sdp: await sdpResponse.text(),\n",
    "  };\n",
    "  await pc.setRemoteDescription(answer);\n",
    "}\n",
    "\n",
    "init();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b7c93-ef7c-4b08-95a9-175f0723e47c",
   "metadata": {},
   "source": [
    "### Creating an ephemeral token\n",
    "To create an ephemeral token to use on the client-side, you will need to build a small server-side application (or integrate with an existing one) to make an OpenAI REST API request for an ephemeral key. You will use a standard API key to authenticate this request on your backend server.\n",
    "\n",
    "Below is an example of a simple Node.js express server which mints an ephemeral API key using the REST API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e886f6c-4eba-4c6a-aa43-f36552b62db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import express from \"express\";\n",
    "\n",
    "const app = express();\n",
    "\n",
    "// An endpoint which would work with the client code above - it returns\n",
    "// the contents of a REST API request to this protected endpoint\n",
    "app.get(\"/session\", async (req, res) => {\n",
    "  const r = await fetch(\"https://api.openai.com/v1/realtime/sessions\", {\n",
    "    method: \"POST\",\n",
    "    headers: {\n",
    "      \"Authorization\": `Bearer ${process.env.OPENAI_API_KEY}`,\n",
    "      \"Content-Type\": \"application/json\",\n",
    "    },\n",
    "    body: JSON.stringify({\n",
    "      model: \"gpt-4o-realtime-preview-2024-12-17\",\n",
    "      voice: \"verse\",\n",
    "    }),\n",
    "  });\n",
    "  const data = await r.json();\n",
    "\n",
    "  // Send back the JSON we received from the OpenAI REST API\n",
    "  res.send(data);\n",
    "});\n",
    "\n",
    "app.listen(3000);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac22bb-ad04-45b0-8383-f8c0aeb27585",
   "metadata": {},
   "source": [
    "### Sending and receiving events\n",
    "To interact with the Realtime models, you will send and receive messages over the WebRTC data channel, and send and receive audio over media streams with the Realtime API as a connected peer. The full list of messages that clients can send, and that will be sent from the server, are found in the API reference. Once connected, you'll send and receive events which represent text, audio, function calls, interruptions, configuration updates, and more.\n",
    "\n",
    "Here is how you can send and receive events over the data channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cc2e85-63e8-48b2-9dc3-7cdc79790549",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a data channel from a peer connection\n",
    "const dc = pc.createDataChannel(\"oai-events\");\n",
    "\n",
    "// Listen for server-sent events on the data channel - event data \n",
    "// will need to be parsed from a JSON string\n",
    "dc.addEventListener(\"message\", (e) => {\n",
    "  const realtimeEvent = JSON.parse(e.data);\n",
    "  console.log(realtimeEvent);\n",
    "});\n",
    "\n",
    "// Send client events by serializing a valid client event to\n",
    "// JSON, and sending it over the data channel\n",
    "const responseCreate = {\n",
    "  type: \"response.create\",\n",
    "  response: {\n",
    "    modalities: [\"text\"],\n",
    "    instructions: \"Write a haiku about code\",\n",
    "  },\n",
    "};\n",
    "dc.send(JSON.stringify(responseCreate));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a594f81a-9ef1-49ed-992b-0e9b527518ce",
   "metadata": {},
   "source": [
    "### Realtime API with WebSockets\n",
    "Use WebSockets to connect to the Realtime API in server-to-server applications.\n",
    "WebSockets are a broadly supported API for realtime data transfer, and a great choice for connecting to the OpenAI Realtime API in server-to-server applications. For browser and mobile clients, we recommend connecting via WebRTC. Follow this guide to connect to the Realtime API via WebSocket and start interacting with a Realtime model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c4a4c-c6b9-43a0-a5c4-e16fdd5b0057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect using the ws module (Node.js)\n",
    "import WebSocket from \"ws\";\n",
    "\n",
    "const url = \"wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17\";\n",
    "const ws = new WebSocket(url, {\n",
    "  headers: {\n",
    "    \"Authorization\": \"Bearer \" + process.env.OPENAI_API_KEY,\n",
    "    \"OpenAI-Beta\": \"realtime=v1\",\n",
    "  },\n",
    "});\n",
    "\n",
    "ws.on(\"open\", function open() {\n",
    "  console.log(\"Connected to server.\");\n",
    "});\n",
    "\n",
    "ws.on(\"message\", function incoming(message) {\n",
    "  console.log(JSON.parse(message.toString()));\n",
    "});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff92538-0909-4156-8c59-67b966b9d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect with websocket-client (Python)\n",
    "# example requires websocket-client library:\n",
    "# pip install websocket-client\n",
    "\n",
    "import os\n",
    "import json\n",
    "import websocket\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "url = \"wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17\"\n",
    "headers = [\n",
    "    \"Authorization: Bearer \" + OPENAI_API_KEY,\n",
    "    \"OpenAI-Beta: realtime=v1\"\n",
    "]\n",
    "\n",
    "def on_open(ws):\n",
    "    print(\"Connected to server.\")\n",
    "\n",
    "def on_message(ws, message):\n",
    "    data = json.loads(message)\n",
    "    print(\"Received event:\", json.dumps(data, indent=2))\n",
    "\n",
    "ws = websocket.WebSocketApp(\n",
    "    url,\n",
    "    header=headers,\n",
    "    on_open=on_open,\n",
    "    on_message=on_message,\n",
    ")\n",
    "\n",
    "ws.run_forever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997280ee-34be-4885-b30f-cbe8764278fd",
   "metadata": {},
   "source": [
    "### In Simple Terms:\n",
    "- It opens a real-time connection with OpenAI.\n",
    "- When OpenAI sends data, it prints the response.\n",
    "- Useful for continuous streaming responses (e.g., live AI conversations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cb9b0c-72e5-4988-91c6-72676907a1ca",
   "metadata": {},
   "source": [
    "### Sending and receiving events\n",
    "To interact with the Realtime models, you will send and receive messages over the WebSocket interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394f1e8-879d-4ab5-8d98-9a9ed1f10e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send and receive messages with websocket-client (Python)\n",
    "# To send a client event, serialize a dictionary to JSON\n",
    "# of the proper event type\n",
    "def on_open(ws):\n",
    "    print(\"Connected to server.\")\n",
    "    \n",
    "    event = {\n",
    "        \"type\": \"response.create\",\n",
    "        \"response\": {\n",
    "            \"modalities\": [\"text\"],\n",
    "            \"instructions\": \"Please assist the user.\"\n",
    "        }\n",
    "    }\n",
    "    ws.send(json.dumps(event))\n",
    "\n",
    "# Receiving messages will require parsing message payloads\n",
    "# from JSON\n",
    "def on_message(ws, message):\n",
    "    data = json.loads(message)\n",
    "    print(\"Received event:\", json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60088d16-f850-479b-a0ff-134c4e3a49a6",
   "metadata": {},
   "source": [
    "### Realtime model capabilities\n",
    "Learn how to manage Realtime sessions, conversations, model responses, and function calls.\n",
    "Once you have connected to the Realtime API through either WebRTC or WebSocket, you can build applications with a Realtime AI model. Doing so will require you to send client events to initiate actions, and listen for server events to respond to actions taken by the Realtime API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646faafb-f48c-45d4-b6fe-607b05ab10fb",
   "metadata": {},
   "source": [
    "### About Realtime sessions\n",
    "A Realtime session is a stateful interaction between the model and a connected client. The key components of the session are:\n",
    "\n",
    "- The session object, which controls the parameters of the interaction, like the model being used, the voice used to generate output, and other configuration.\n",
    "- A conversation, which represents user inputs and model outputs generated during the current session.\n",
    "- Responses, which are model-generated audio or text outputs that are added to the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382e0df2-f216-4545-9390-a2b5abda74b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the system instructions used by the model in this session\n",
    "event = {\n",
    "    \"type\": \"session.update\",\n",
    "    \"session\": {\n",
    "        \"instructions\": \"Never use the word 'moist' in your responses!\"\n",
    "    }\n",
    "}\n",
    "ws.send(json.dumps(event))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3419d68c-1ba4-44ab-b1bb-3b331164f9ac",
   "metadata": {},
   "source": [
    "### Text inputs and outputs\n",
    "To generate text with a Realtime model, you can add text inputs to the current conversation, ask the model to generate a response, and listen for server-sent events indicating the progress of the model's response. In order to generate text, the session must be configured with the text modality (this is true by default).\n",
    "\n",
    "Create a new text conversation item using the __conversation.item.create__ client event. This is similar to sending a user message (prompt) in chat completions in the REST API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16fd7e-d812-4cf0-8f0f-24c19f3b5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a conversation item with user input\n",
    "event = {\n",
    "    \"type\": \"conversation.item.create\",\n",
    "    \"item\": {\n",
    "        \"type\": \"message\",\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"input_text\",\n",
    "                \"text\": \"What Prince album sold the most copies?\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "ws.send(json.dumps(event))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf33e50-bafa-41d9-b943-5452b88563a4",
   "metadata": {},
   "source": [
    "After adding the user message to the conversation, send the __response.create__ event to initiate a response from the model. If both audio and text are enabled for the current session, the model will respond with both audio and text content. If you'd like to generate text only, you can specify that when sending the response.create client event, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c98e9-2264-41ca-a46f-e502c93d4adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a text-only response\n",
    "event = {\n",
    "    \"type\": \"response.create\",\n",
    "    \"response\": {\n",
    "        \"modalities\": [\"text\"]\n",
    "    }\n",
    "}\n",
    "ws.send(json.dumps(event))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33705ef2-4ccb-41ec-b261-8660b8b6151b",
   "metadata": {},
   "source": [
    "When the response is completely finished, the server will emit the __response.done__ event. This event will contain the full text generated by the model, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c16ad-ecd2-4870-a3ef-ead7b7f4beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listen for response.done to see the final results\n",
    "def on_message(ws, message):\n",
    "    server_event = json.loads(message)\n",
    "    if server_event.type == \"response.done\":\n",
    "        print(server_event.response.output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83f2de-c479-40a8-bf3e-9b887e232a94",
   "metadata": {},
   "source": [
    "### Audio inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba368689-e8f9-4658-a4c8-a0eb4b134dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a peer connection\n",
    "const pc = new RTCPeerConnection();\n",
    "\n",
    "// Set up to play remote audio from the model\n",
    "const audioEl = document.createElement(\"audio\");\n",
    "audioEl.autoplay = true;\n",
    "pc.ontrack = e => audioEl.srcObject = e.streams[0];\n",
    "\n",
    "// Add local audio track for microphone input in the browser\n",
    "const ms = await navigator.mediaDevices.getUserMedia({\n",
    "  audio: true\n",
    "});\n",
    "pc.addTrack(ms.getTracks()[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3078f-8b30-41bb-b918-531ecbce0fb4",
   "metadata": {},
   "source": [
    "### Client and server events for audio in WebRTC\n",
    "By default, WebRTC clients don't need to send any client events to the Realtime API to start sending audio inputs. Once a local audio track is added to the peer connection, your users can just start talking!\n",
    "\n",
    "However, WebRTC clients still receive a number of server-sent lifecycle events as audio is moving back and forth between client and server over the peer connection. An incomplete sample of server events that are sent during a WebRTC session:\n",
    "\n",
    "- When input is sent over the local media track, you will receive __input_audio_buffer.speech_started__ events from the server.\n",
    "- When local audio input stops, you'll receive the __input_audio_buffer.speech_stopped__ event.\n",
    "- You'll receive delta events for the in-progress audio transcript.\n",
    "- You'll receive a __response.done__ event when the model has transcribed and completed sending a response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d080809-5ba2-4e3e-b619-438755ea4be3",
   "metadata": {},
   "source": [
    "### Streaming audio input to the server\n",
    "To stream audio input to the server, you can use the __input_audio_buffer.append__ client event. This event requires you to send chunks of Base64-encoded audio bytes to the Realtime API over the socket. Each chunk cannot exceed 15 MB in size.\n",
    "\n",
    "The format of the input chunks can be configured either for the entire session, or per response.\n",
    "\n",
    "- Session: session.input_audio_format in session.update\n",
    "- Response: response.input_audio_format in response.create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d17b96c-fcce-4855-b4bc-33f1d3497204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append audio input bytes to the conversation\n",
    "import base64\n",
    "import json\n",
    "import struct\n",
    "import soundfile as sf\n",
    "from websocket import create_connection\n",
    "\n",
    "# ... create websocket-client named ws ...\n",
    "\n",
    "def float_to_16bit_pcm(float32_array): # it scales and converts floating-point audio values (-1.0 to 1.0) into 16-bit PCM binary data.\n",
    "    clipped = [max(-1.0, min(1.0, x)) for x in float32_array]\n",
    "    pcm16 = b''.join(struct.pack('<h', int(x * 32767)) for x in clipped) #b'' creates an empty byte string. < → Little-endian byte order (least significant byte first).\n",
    "    return pcm16 #h → 16-bit signed integer (-32768 to 32767).\n",
    "\n",
    "def base64_encode_audio(float32_array):\n",
    "    pcm_bytes = float_to_16bit_pcm(float32_array) # Converts binary PCM data into Base64 encoding (text-based format for safe transmission).\n",
    "    encoded = base64.b64encode(pcm_bytes).decode('ascii') #Converts the Base64 bytes into a string.\n",
    "    return encoded\n",
    "\n",
    "files = [\n",
    "    './path/to/sample1.wav',\n",
    "    './path/to/sample2.wav',\n",
    "    './path/to/sample3.wav'\n",
    "]\n",
    "\n",
    "for filename in files:\n",
    "    data, samplerate = sf.read(filename, dtype='float32')  \n",
    "    channel_data = data[:, 0] if data.ndim > 1 else data\n",
    "    base64_chunk = base64_encode_audio(channel_data)\n",
    "    \n",
    "    # Send the client event\n",
    "    event = {\n",
    "        \"type\": \"input_audio_buffer.append\",\n",
    "        \"audio\": base64_chunk\n",
    "    }\n",
    "    ws.send(json.dumps(event))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8757c327-0a1a-4b23-8fd6-92dfe4b624bf",
   "metadata": {},
   "source": [
    "### Send full audio messages\n",
    "It is also possible to create conversation messages that are full audio recordings. Use the conversation.item.create client event to create messages with input_audio content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a2aa9-779c-4333-991b-4e88082a8c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full audio input conversation items\n",
    "fullAudio = \"<a base64-encoded string of audio bytes>\"\n",
    "\n",
    "event = {\n",
    "    \"type\": \"conversation.item.create\",\n",
    "    \"item\": {\n",
    "        \"type\": \"message\",\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"input_audio\",\n",
    "                \"audio\": fullAudio,\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "ws.send(json.dumps(event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d25212e-3ed5-4004-a173-87153a0cc331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listen for response.audio.delta events\n",
    "def on_message(ws, message):\n",
    "    server_event = json.loads(message)\n",
    "    if server_event.type == \"response.audio.delta\":\n",
    "        #access Base64-encoded audio chunks:\n",
    "        #print(server_event.delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa447047-b74f-4113-931e-148c0580746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an out-of-band model response\n",
    "prompt = \"\"\"\n",
    "Analyze the conversation so far. If it is related to support, output\n",
    "\"support\". If it is related to sales, output \"sales\".\n",
    "\"\"\"\n",
    "\n",
    "event = {\n",
    "    \"type\": \"response.create\",\n",
    "    \"response\": {\n",
    "        # Setting to \"none\" indicates the response is out of band,\n",
    "        # and will not be added to the default conversation\n",
    "        \"conversation\": \"none\",\n",
    "\n",
    "        # Set metadata to help identify responses sent back from the model\n",
    "        \"metadata\": { \"topic\": \"classification\" },\n",
    "\n",
    "        # Set any other available response fields\n",
    "        \"modalities\": [ \"text\" ],\n",
    "        \"instructions\": prompt,\n",
    "    },\n",
    "}\n",
    "\n",
    "ws.send(json.dumps(event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acbbbd0-c80a-4236-8a9f-ee7333abc9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an out-of-band model response\n",
    "def on_message(ws, message):\n",
    "    server_event = json.loads(message)\n",
    "    topic = \"\"\n",
    "\n",
    "    #see if metadata is present \n",
    "    try:\n",
    "        topic = server_event.response.metadata.topic\n",
    "    except AttributeError:\n",
    "        print(\"topic not set\")\n",
    "\n",
    "    if server_event.type == \"response.cone\" and topic ==\"classification\":\n",
    "        # this server event pertained to our OOB model response \n",
    "        print(server_event.response.output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e36a4-462d-4953-993e-e4f196fb4422",
   "metadata": {},
   "source": [
    "### Create a custom context for responses\n",
    "You can also construct a custom context that the model will use to generate a response, outside the default/current conversation. This can be done using the input array on a response.create client event. You can use new inputs, or reference existing input items in the conversation by ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de709d6a-0623-4cb3-b8ef-280c12e33d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listen for out-of-band model response with custom context\n",
    "event = {\n",
    "    \"type\": \"response.create\",\n",
    "    \"response\": {\n",
    "        \"conversation\": \"none\",\n",
    "        \"metadata\": { \"topic\": \"pizza\" },\n",
    "        \"modalities\": [ \"text\" ],\n",
    "\n",
    "        # Create a custom input array for this request with whatever \n",
    "        # context is appropriate\n",
    "        \"input\": [\n",
    "            # potentially include existing conversation items:\n",
    "            {\n",
    "                \"type\": \"item_reference\",\n",
    "                \"id\": \"some_conversation_item_id\"\n",
    "            },\n",
    "\n",
    "            # include new content as well\n",
    "            {\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": \"Is it okay to put pineapple on pizza?\",\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "ws.send(json.dumps(event))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30e3232-b3fe-4359-9e07-6d058fcfe3bb",
   "metadata": {},
   "source": [
    "### Create responses with no context\n",
    "You can also insert responses into the default conversation, ignoring all other instructions and context. Do this by setting __input__ to an empty array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a558c786-8d0d-459e-953d-3fff144e4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert no-context model responses into the default conversation\n",
    "prompt = \"\"\"\n",
    "Say exactly the following:\n",
    "I'm a little teapot, short and stout! \n",
    "This is my handle, this is my spout!\n",
    "\"\"\"\n",
    "\n",
    "event = {\n",
    "    \"type\": \"response.create\",\n",
    "    \"response\": {\n",
    "        # An empty input array removes all prior context\n",
    "        \"input\": [],\n",
    "        \"instructions\": prompt,\n",
    "    },\n",
    "}\n",
    "\n",
    "ws.send(json.dumps(event))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695fe735-ec11-4286-8872-a31d398d207e",
   "metadata": {},
   "source": [
    "### Function calling\n",
    "The Realtime models also support function calling, which enables you to execute custom code to extend the capabilities of the model. Here's how it works at a high level:\n",
    "\n",
    "1. When updating the session or creating a response, you can specify a list of available functions for the model to call.\n",
    "2. If when processing input, the model determines it should make a function call, it will add items to the conversation representing arguments to a function call.\n",
    "3. When the client detects conversation items that contain function call arguments, it will execute custom code using those arguments\n",
    "4. When the custom code has been executed, the client will create new conversation items that contain the output of the function call, and ask the model to respond."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18cae70-17bf-4dd1-82e2-9a41bf5c41a1",
   "metadata": {},
   "source": [
    "### Configure callable functions\n",
    "First, we must give the model a selection of functions it can call based on user input. Available functions can be configured either at the session level, or the individual response level.\n",
    "\n",
    "- Session: session.tools property in __session.update__\n",
    "- Response: response.tools property in __response.create__\n",
    "\n",
    "Here's an example client event payload for a session.update that configures a horoscope generation function, that takes a single argument (the astrological sign for which the horoscope should be generated):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6411f24-3241-4315-8130-2e987b08a806",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"type\": \"session.update\",\n",
    "  \"session\": {\n",
    "    \"tools\": [\n",
    "      {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"generate_horoscope\",\n",
    "        \"description\": \"Give today's horoscope for an astrological sign.\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"sign\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"The sign for the horoscope.\",\n",
    "              \"enum\": [\n",
    "                \"Aries\",\n",
    "                \"Taurus\",\n",
    "                \"Gemini\",\n",
    "                \"Cancer\",\n",
    "                \"Leo\",\n",
    "                \"Virgo\",\n",
    "                \"Libra\",\n",
    "                \"Scorpio\",\n",
    "                \"Sagittarius\",\n",
    "                \"Capricorn\",\n",
    "                \"Aquarius\",\n",
    "                \"Pisces\"\n",
    "              ]\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\"sign\"]\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"tool_choice\": \"auto\",\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb78c655-fe24-45c6-a459-0d6a27447ee8",
   "metadata": {},
   "source": [
    "### Detect when the model wants to call a function\n",
    "Based on inputs to the model, the model may decide to call a function in order to generate the best response. Let's say our application adds the following conversation item and attempts to generate a response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22da59c-7ce6-4942-bec3-c74a04578074",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"type\": \"conversation.item.create\",\n",
    "    \"item\": {\n",
    "        \"type\": \"message\",\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"input_text\",\n",
    "                \"text\": \"What is my horoscope? I am an aquarius.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d439a86e-758b-4d8b-b160-1de1ef3117f9",
   "metadata": {},
   "source": [
    "Followed by a client event to generate a response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2300a4-4cb6-47c7-ad23-a26fd40d6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"type\": \"response.create\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe445b67-647d-4a0f-a554-e7b109a86cda",
   "metadata": {},
   "source": [
    "Instead of immediately returning a text or audio response, the model will instead generate a response that contains the arguments that should be passed to a function in the developer's application. You can listen for realtime updates to function call arguments using the response.function_call_arguments.delta server event, but response.done will also have the complete data we need to call our function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c0805-204a-49e8-96a0-17580c2771a7",
   "metadata": {},
   "source": [
    "__response.done__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc1b99-c720-4dfa-8d80-566766f95587",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"type\": \"response.done\",\n",
    "  \"event_id\": \"event_AeqLA8iR6FK20L4XZs2P6\",\n",
    "  \"response\": {\n",
    "    \"object\": \"realtime.response\",\n",
    "    \"id\": \"resp_AeqL8XwMUOri9OhcQJIu9\",\n",
    "    \"status\": \"completed\",\n",
    "    \"status_details\": null,\n",
    "    \"output\": [\n",
    "      {\n",
    "        \"object\": \"realtime.item\",\n",
    "        \"id\": \"item_AeqL8gmRWDn9bIsUM2T35\",\n",
    "        \"type\": \"function_call\",\n",
    "        \"status\": \"completed\",\n",
    "        \"name\": \"generate_horoscope\",\n",
    "        \"call_id\": \"call_sHlR7iaFwQ2YQOqm\",\n",
    "        \"arguments\": \"{\\\"sign\\\":\\\"Aquarius\\\"}\"\n",
    "      }\n",
    "    ],\n",
    "    \"usage\": {\n",
    "      \"total_tokens\": 541,\n",
    "      \"input_tokens\": 521,\n",
    "      \"output_tokens\": 20,\n",
    "      \"input_token_details\": {\n",
    "        \"text_tokens\": 292,\n",
    "        \"audio_tokens\": 229,\n",
    "        \"cached_tokens\": 0,\n",
    "        \"cached_tokens_details\": { \"text_tokens\": 0, \"audio_tokens\": 0 }\n",
    "      },\n",
    "      \"output_token_details\": {\n",
    "        \"text_tokens\": 20,\n",
    "        \"audio_tokens\": 0\n",
    "      }\n",
    "    },\n",
    "    \"metadata\": null\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ade021-4950-43c9-894a-ee466dfc72b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"type\": \"conversation.item.create\",\n",
    "  \"item\": {\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": \"call_sHlR7iaFwQ2YQOqm\",\n",
    "    \"output\": \"{\\\"horoscope\\\": \\\"You will soon meet a new friend.\\\"}\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2430d-c372-42e6-a7fe-a7f1ea601565",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"type\": \"response.create\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69c8a6-8eb3-451c-9415-b87de5506e4e",
   "metadata": {},
   "source": [
    "### Error handling\n",
    "The error event is emitted by the server whenever an error condition is encountered on the server during the session. Occasionally, these errors can be traced to a client event that was emitted by your application.\n",
    "\n",
    "Unlike HTTP requests and responses, where a response is implicitly tied to a request from the client, we need to use an __event_id__ property on client events to know when one of them has triggered an error condition on the server. This technique is shown in the code below, where the client attempts to emit an unsupported event type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa4bf32-5afa-4633-b3c9-6f8fee757c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "const event = {\n",
    "  event_id: \"my_awesome_event\",\n",
    "  type: \"scooby.dooby.doo\",\n",
    "};\n",
    "\n",
    "dataChannel.send(JSON.stringify(event));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f0390e-71c5-404b-a9ea-2d48b270c7f8",
   "metadata": {},
   "source": [
    "This unsuccessful event sent from the client will emit an error event like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d43ae7-4c1a-4a1b-bca2-a3ba11cc69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"type\": \"invalid_request_error\",\n",
    "  \"code\": \"invalid_value\",\n",
    "  \"message\": \"Invalid value: 'scooby.dooby.doo' ...\",\n",
    "  \"param\": \"type\",\n",
    "  \"event_id\": \"my_awesome_event\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
